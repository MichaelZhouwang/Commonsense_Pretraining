/home/bill/CommonGen-plus/dataset/final_data/commongen/commongen.test.src_alpha.txt
/home/bill/CommonGen-plus/dataset/final_data/commongen/commongen.test.tgt.txt
/home/bill/CommonGen-plus/methods/unilm_based/decoded_sentences/test/model.10.bin.test
Start running ROUGE
here!!!!!!!!!!!!!
1
---------------------------------------------
1 ROUGE-1 Average_R: 0.50747 (95%-conf.int. 0.50348 - 0.51158)
1 ROUGE-1 Average_P: 0.63010 (95%-conf.int. 0.62616 - 0.63428)
1 ROUGE-1 Average_F: 0.55088 (95%-conf.int. 0.54727 - 0.55446)
---------------------------------------------
1 ROUGE-2 Average_R: 0.19875 (95%-conf.int. 0.19424 - 0.20311)
1 ROUGE-2 Average_P: 0.24504 (95%-conf.int. 0.23972 - 0.24994)
1 ROUGE-2 Average_F: 0.21483 (95%-conf.int. 0.21005 - 0.21924)
---------------------------------------------
1 ROUGE-L Average_R: 0.40538 (95%-conf.int. 0.40112 - 0.40957)
1 ROUGE-L Average_P: 0.49913 (95%-conf.int. 0.49483 - 0.50346)
1 ROUGE-L Average_F: 0.43867 (95%-conf.int. 0.43481 - 0.44268)

/home/bill/CommonGen-plus/methods/unilm_based/decoded_sentences/test/model.10.bin.test
>> ROUGE-F(1/2/l): 55.09/21.48/43.87
ROUGE-R(1/2/l): 50.75/19.88/40.54

BLEU/METER/CIDER/SPICE
SPICE evaluation took: 2.618 s
tokenization...
setting up scorers...
computing Bleu score...
{'reflen': 18237, 'guess': [16799, 15302, 13805, 12308], 'testlen': 16799, 'correct': [13043, 6552, 3006, 1416]}
ratio: 0.921149311839
Bleu_1: 0.713
Bleu_2: 0.529
Bleu_3: 0.383
Bleu_4: 0.277
computing METEOR score...
METEOR: 0.297
computing CIDEr score...
CIDEr: 1.485
computing SPICE score...
SPICE: 0.302
Coverage
System level Coverage: 89.19
